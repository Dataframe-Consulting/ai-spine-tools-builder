# Advanced Usage

Advanced techniques, patterns, and best practices for building production-ready AI Spine tools.

## Overview

This section covers advanced topics for developers who want to build sophisticated, production-ready AI Spine tools with advanced features, optimal performance, and enterprise-grade reliability.

## Available Guides

### üîí [Security Best Practices](security.md)
Comprehensive security implementation for AI Spine tools.

- Authentication and authorization patterns
- Input validation and sanitization
- Data protection and encryption
- Network security and HTTPS
- API security best practices
- Secure configuration management

### üß™ [Testing Strategies](testing.md)
Complete testing approaches for AI Spine tools.

- Unit testing with Jest
- Integration testing patterns
- End-to-end testing strategies
- Performance testing techniques
- Security testing methods
- Test automation and CI/CD

### ‚ö° [Performance Optimization](performance.md)
Techniques for optimizing AI Spine tool performance.

- Memory management and optimization
- CPU usage optimization
- Database query optimization
- Caching strategies
- Concurrent processing
- Load balancing and scaling

### üõ†Ô∏è [Error Handling](error-handling.md)
Advanced error handling and recovery patterns.

- Error classification and handling
- Graceful degradation patterns
- Circuit breaker implementation
- Retry logic and backoff strategies
- Error logging and monitoring
- Recovery procedures

## Advanced Patterns

### Complex Tool Architectures

#### Multi-Step Workflows
```typescript
import { createTool } from '@ai-spine/tools';

const workflowTool = createTool({
  metadata: {
    name: 'multi-step-workflow',
    description: 'Execute complex multi-step workflows'
  },
  schema: {
    input: {
      steps: arrayField({
        description: 'Workflow steps to execute',
        itemType: 'object',
        required: true
      })
    }
  },
  execute: async ({ input }) => {
    const results = [];
    const context = {};
    
    for (const [index, step] of input.steps.entries()) {
      try {
        const stepResult = await executeStep(step, context, results);
        results.push({ step: index, result: stepResult });
        
        // Update context for next steps
        context[step.id] = stepResult;
      } catch (error) {
        // Handle step failure
        if (step.required !== false) {
          throw new Error(`Required step ${index} failed: ${error.message}`);
        }
        results.push({ step: index, error: error.message, skipped: true });
      }
    }
    
    return { workflow: results, context };
  }
});
```

#### Plugin System
```typescript
interface ToolPlugin {
  name: string;
  version: string;
  beforeExecute?(context: ToolExecutionContext): Promise<void>;
  afterExecute?(context: ToolExecutionContext, result: any): Promise<any>;
  onError?(context: ToolExecutionContext, error: Error): Promise<void>;
}

class ExtensibleTool extends Tool {
  private plugins: ToolPlugin[] = [];
  
  registerPlugin(plugin: ToolPlugin) {
    this.plugins.push(plugin);
  }
  
  async execute(context: ToolExecutionContext) {
    // Run before hooks
    for (const plugin of this.plugins) {
      if (plugin.beforeExecute) {
        await plugin.beforeExecute(context);
      }
    }
    
    try {
      let result = await super.execute(context);
      
      // Run after hooks
      for (const plugin of this.plugins) {
        if (plugin.afterExecute) {
          result = await plugin.afterExecute(context, result) || result;
        }
      }
      
      return result;
    } catch (error) {
      // Run error hooks
      for (const plugin of this.plugins) {
        if (plugin.onError) {
          await plugin.onError(context, error);
        }
      }
      throw error;
    }
  }
}
```

### Advanced Schema Patterns

#### Conditional Fields
```typescript
const schema = {
  input: {
    type: enumField({
      description: 'Operation type',
      values: ['email', 'sms', 'webhook'],
      required: true
    }),
    // Conditional fields based on type
    emailConfig: objectField({
      description: 'Email configuration',
      required: false,
      condition: (input) => input.type === 'email',
      properties: {
        to: stringField({ format: 'email', required: true }),
        subject: stringField({ required: true }),
        template: stringField({ required: true })
      }
    }),
    smsConfig: objectField({
      description: 'SMS configuration',
      required: false,
      condition: (input) => input.type === 'sms',
      properties: {
        phoneNumber: stringField({ pattern: '^\\+[1-9]\\d{1,14}$', required: true }),
        message: stringField({ maxLength: 160, required: true })
      }
    })
  }
};
```

#### Dynamic Schema Generation
```typescript
const createDynamicSchema = (templateConfig: any) => {
  const inputFields: Record<string, any> = {};
  
  for (const [key, config] of Object.entries(templateConfig.fields)) {
    switch (config.type) {
      case 'string':
        inputFields[key] = stringField(config.options);
        break;
      case 'number':
        inputFields[key] = numberField(config.options);
        break;
      case 'array':
        inputFields[key] = arrayField(config.options);
        break;
      default:
        throw new Error(`Unsupported field type: ${config.type}`);
    }
  }
  
  return { input: inputFields };
};
```

### Advanced Execution Patterns

#### Streaming Responses
```typescript
import { Readable } from 'stream';

const streamingTool = createTool({
  // ... metadata and schema
  execute: async ({ input }) => {
    const stream = new Readable({
      objectMode: true,
      read() {}
    });
    
    // Start processing in background
    processLargeDataset(input.dataSource, {
      onProgress: (chunk) => {
        stream.push({ progress: chunk.progress, data: chunk.data });
      },
      onComplete: (finalResult) => {
        stream.push({ completed: true, result: finalResult });
        stream.push(null); // End stream
      },
      onError: (error) => {
        stream.destroy(error);
      }
    });
    
    return { stream };
  }
});
```

#### Parallel Processing
```typescript
import pLimit from 'p-limit';

const limit = pLimit(5); // Limit concurrent operations

const parallelTool = createTool({
  // ... metadata and schema
  execute: async ({ input }) => {
    const tasks = input.items.map(item =>
      limit(async () => {
        try {
          return await processItem(item);
        } catch (error) {
          return { error: error.message, item };
        }
      })
    );
    
    const results = await Promise.all(tasks);
    
    const successful = results.filter(r => !r.error);
    const failed = results.filter(r => r.error);
    
    return {
      processed: successful.length,
      failed: failed.length,
      results: successful,
      errors: failed
    };
  }
});
```

## Enterprise Features

### Multi-Tenancy
```typescript
interface TenantContext {
  tenantId: string;
  permissions: string[];
  resources: Record<string, any>;
}

const multiTenantTool = createTool({
  // ... basic configuration
  execute: async ({ input, config, headers }) => {
    const tenantContext = await resolveTenantContext(headers['x-tenant-id']);
    
    // Validate tenant permissions
    if (!tenantContext.permissions.includes('read_data')) {
      throw new Error('Insufficient permissions');
    }
    
    // Use tenant-specific resources
    const database = getTenantDatabase(tenantContext.tenantId);
    const result = await database.query('SELECT * FROM tenant_data WHERE id = ?', [input.id]);
    
    return { data: result, tenant: tenantContext.tenantId };
  }
});
```

### Audit Logging
```typescript
interface AuditEvent {
  timestamp: string;
  userId: string;
  action: string;
  resource: string;
  metadata: Record<string, any>;
}

const auditLogger = {
  log: async (event: AuditEvent) => {
    // Store in audit database
    await auditDB.insert('audit_log', {
      ...event,
      id: generateId(),
      timestamp: new Date().toISOString()
    });
  }
};

const auditedTool = createTool({
  // ... configuration
  execute: async ({ input, config, context }) => {
    await auditLogger.log({
      timestamp: new Date().toISOString(),
      userId: context.userId,
      action: 'tool_execution',
      resource: 'data_processor',
      metadata: { inputHash: hashInput(input) }
    });
    
    const result = await processData(input);
    
    await auditLogger.log({
      timestamp: new Date().toISOString(),
      userId: context.userId,
      action: 'tool_completion',
      resource: 'data_processor',
      metadata: { success: true, recordsProcessed: result.count }
    });
    
    return result;
  }
});
```

### Rate Limiting
```typescript
import { RateLimiterMemory } from 'rate-limiter-flexible';

const rateLimiter = new RateLimiterMemory({
  keyPrefix: 'tool_rate_limit',
  points: 100, // Number of requests
  duration: 60, // Per 60 seconds
});

const rateLimitedTool = createTool({
  // ... configuration
  execute: async ({ input, context }) => {
    const key = `user_${context.userId}`;
    
    try {
      await rateLimiter.consume(key);
    } catch (rejRes) {
      throw new Error(`Rate limit exceeded. Try again in ${Math.round(rejRes.msBeforeNext / 1000)} seconds.`);
    }
    
    return await processRequest(input);
  }
});
```

## Advanced Configuration

### Environment-Specific Configuration
```typescript
interface EnvironmentConfig {
  database: {
    url: string;
    poolSize: number;
    timeout: number;
  };
  redis: {
    url: string;
    keyPrefix: string;
  };
  external: {
    apiUrl: string;
    timeout: number;
    retries: number;
  };
}

const getConfig = (): EnvironmentConfig => {
  const env = process.env.NODE_ENV || 'development';
  
  const baseConfig = {
    development: {
      database: { url: 'localhost:5432', poolSize: 5, timeout: 5000 },
      redis: { url: 'localhost:6379', keyPrefix: 'dev:' },
      external: { apiUrl: 'http://localhost:3001', timeout: 5000, retries: 3 }
    },
    production: {
      database: { url: process.env.DATABASE_URL!, poolSize: 20, timeout: 10000 },
      redis: { url: process.env.REDIS_URL!, keyPrefix: 'prod:' },
      external: { apiUrl: process.env.API_URL!, timeout: 30000, retries: 5 }
    }
  };
  
  return baseConfig[env] || baseConfig.development;
};
```

### Feature Flags
```typescript
interface FeatureFlags {
  enableNewAlgorithm: boolean;
  useAdvancedValidation: boolean;
  enableMetrics: boolean;
}

const getFeatureFlags = async (context: any): Promise<FeatureFlags> => {
  // Fetch from feature flag service
  const flags = await featureFlagService.getFlags(context.userId);
  
  return {
    enableNewAlgorithm: flags.new_algorithm === true,
    useAdvancedValidation: flags.advanced_validation === true,
    enableMetrics: flags.metrics === true
  };
};

const featureFlaggedTool = createTool({
  // ... configuration
  execute: async ({ input, context }) => {
    const flags = await getFeatureFlags(context);
    
    let result;
    if (flags.enableNewAlgorithm) {
      result = await newAlgorithm(input);
    } else {
      result = await legacyAlgorithm(input);
    }
    
    if (flags.enableMetrics) {
      await recordMetrics(result);
    }
    
    return result;
  }
});
```

## Performance Considerations

### Memory Management
- Use streaming for large data processing
- Implement proper cleanup in finally blocks
- Monitor memory usage and implement alerts
- Use object pooling for frequently created objects

### Concurrency Control
- Implement proper locking mechanisms
- Use connection pooling for databases
- Control concurrent operations with semaphores
- Handle race conditions appropriately

### Caching Strategies
- Implement multi-level caching
- Use appropriate cache invalidation strategies
- Monitor cache hit rates and effectiveness
- Consider distributed caching for scalability

## Best Practices

### Code Organization
- Separate business logic from framework code
- Use dependency injection for testability
- Implement proper error boundaries
- Follow SOLID principles

### Documentation
- Document all public APIs
- Provide comprehensive examples
- Maintain up-to-date troubleshooting guides
- Include performance characteristics

### Testing
- Achieve high test coverage (>90%)
- Test edge cases and error conditions
- Use integration tests for complex workflows
- Implement performance regression tests

## Next Steps

Choose your advanced topic based on your needs:

1. **üîí Security Focus**: Start with [Security Best Practices](security.md)
2. **üß™ Quality Assurance**: Implement [Testing Strategies](testing.md)
3. **‚ö° Performance**: Optimize with [Performance Techniques](performance.md)
4. **üõ†Ô∏è Reliability**: Implement [Error Handling](error-handling.md)

Each guide provides detailed implementations, real-world examples, and production-ready patterns.